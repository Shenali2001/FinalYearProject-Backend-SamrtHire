{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-26T04:41:49.431994Z",
     "start_time": "2025-07-26T04:41:49.427946Z"
    }
   },
   "source": [
    "import json\n",
    "data = []\n",
    "try:\n",
    "    with open('converted_dataset_clean.json', 'r') as file:\n",
    "        data = json.load(file)\n",
    "    print(f\"Total entries parsed: {len(data)}\")\n",
    "    print(\"First 5 entries:\", data[:5])\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"Error parsing file: {e}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries parsed: 2541\n",
      "First 5 entries: [{'input': 'CV section: Financial Accountant specializing in financial planning, reporting, and analysis within the Department of Defense.', 'output': 'Please give a brief introduction about yourself based on your CV.'}, {'input': 'CV section: Associate in Accounting, Northern Maine Community College, 1994, GPA: 3.41; Attended Hudson College, major in Accounting, 78 semester hours toward Bachelor’s degree; Professional Military Comptroller School, 6 weeks, 1998; Certified Defense Financial Manager, CDFM, May 2005.', 'output': 'What educational qualifications do you have in accounting?'}, {'input': 'Question: What educational qualifications do you have in accounting?\\nAnswer: I have an Associate in Accounting from Northern Maine Community College with a GPA of 3.41, 78 semester hours toward a Bachelor’s in Accounting from Hudson College, and a Certified Defense Financial Manager certification from 2005.', 'label': 'correct'}, {'input': 'Question: What educational qualifications do you have in accounting?\\nAnswer: I have a Master’s in Accounting from Hudson College and a CPA certification.', 'label': 'incorrect'}, {'input': 'CV section: Associate in Accounting, Northern Maine Community College, 1994, GPA: 3.41; Attended Hudson College, major in Accounting, 78 semester hours toward Bachelor’s degree; Professional Military Comptroller School, 6 weeks, 1998; Certified Defense Financial Manager, CDFM, May 2005.', 'output': 'How did your training at the Professional Military Comptroller School enhance your skills as a Financial Accountant?'}]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T04:41:53.248931Z",
     "start_time": "2025-07-26T04:41:51.986869Z"
    }
   },
   "cell_type": "code",
   "source": "!pip3 install scikit-learn\n",
   "id": "8a2805ad5c525f40",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (1.7.1)\r\n",
      "Requirement already satisfied: numpy>=1.22.0 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from scikit-learn) (2.2.6)\r\n",
      "Requirement already satisfied: scipy>=1.8.0 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from scikit-learn) (1.15.3)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from scikit-learn) (1.5.1)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\r\n",
      "\u001B[33mWARNING: There was an error checking the latest version of pip.\u001B[0m\u001B[33m\r\n",
      "\u001B[0m"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T04:41:54.150414Z",
     "start_time": "2025-07-26T04:41:54.145177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "classification_data = []\n",
    "for entry in data:\n",
    "    if isinstance(entry, dict) and \"input\" in entry and \"label\" in entry:\n",
    "        if \"Question:\" in entry[\"input\"] and \"Answer:\" in entry[\"input\"]:\n",
    "            input_text = entry[\"input\"]\n",
    "            label = 1 if entry[\"label\"] == \"correct\" else 0\n",
    "            classification_data.append({\"text\": input_text, \"label\": label})\n",
    "print(f\"Classification entries found: {len(classification_data)}\")\n",
    "if len(classification_data) == 0:\n",
    "    print(\"No classification entries found. Printing sample entries for debugging:\")\n",
    "    print(data[:10])\n",
    "    raise ValueError(\"No valid classification entries found. Check dataset structure.\")\n",
    "train_data, val_data = train_test_split(classification_data, test_size=0.2, random_state=42)\n",
    "print(f\"Training entries: {len(train_data)}, Validation entries: {len(val_data)}\")"
   ],
   "id": "9c4f38d4e7583dfa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification entries found: 1680\n",
      "Training entries: 1344, Validation entries: 336\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T04:41:56.951161Z",
     "start_time": "2025-07-26T04:41:55.721362Z"
    }
   },
   "cell_type": "code",
   "source": "!pip3 install transformers datasets",
   "id": "b419be88efb509db",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (4.53.3)\r\n",
      "Requirement already satisfied: datasets in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (4.0.0)\r\n",
      "Requirement already satisfied: filelock in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from transformers) (3.18.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from transformers) (0.33.4)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from transformers) (2.2.6)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from transformers) (25.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from transformers) (6.0.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from transformers) (2024.11.6)\r\n",
      "Requirement already satisfied: requests in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from transformers) (2.32.4)\r\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from transformers) (0.21.2)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from transformers) (0.5.3)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from transformers) (4.67.1)\r\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from datasets) (21.0.0)\r\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from datasets) (0.3.8)\r\n",
      "Requirement already satisfied: pandas in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from datasets) (2.3.1)\r\n",
      "Requirement already satisfied: xxhash in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from datasets) (3.5.0)\r\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from datasets) (0.70.16)\r\n",
      "Requirement already satisfied: fsspec[http]<=2025.3.0,>=2023.1.0 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from datasets) (2025.3.0)\r\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.14)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from requests->transformers) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from requests->transformers) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from requests->transformers) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from requests->transformers) (2025.7.14)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from pandas->datasets) (2025.2)\r\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\r\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (5.0.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\r\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\r\n",
      "\u001B[33mWARNING: There was an error checking the latest version of pip.\u001B[0m\u001B[33m\r\n",
      "\u001B[0m"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T04:41:57.928698Z",
     "start_time": "2025-07-26T04:41:57.926277Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import transformers\n",
    "import datasets\n",
    "print(\"Libraries installed successfully\")"
   ],
   "id": "8ecdf98ab21adeaa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries installed successfully\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T04:42:02.654852Z",
     "start_time": "2025-07-26T04:42:00.207635Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import BertTokenizer\n",
    "from datasets import Dataset\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding=\"max_length\", truncation=True, max_length=512)\n",
    "train_dataset = Dataset.from_list(train_data)\n",
    "val_dataset = Dataset.from_list(val_data)\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_val = val_dataset.map(tokenize_function, batched=True)"
   ],
   "id": "3016489babd6de0f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/1344 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4be17315e4494d0a874b7b5f4f010371"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/336 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cb36f88e1e4241e9958fb59ea2558995"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T04:42:04.312203Z",
     "start_time": "2025-07-26T04:42:04.309499Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"Training dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")"
   ],
   "id": "e7ee159504b78be0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 1344\n",
      "Validation dataset size: 336\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T04:42:06.327787Z",
     "start_time": "2025-07-26T04:42:06.324410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('converted_dataset_clean.json', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "print(\"First 10 lines of the file:\")\n",
    "for i, line in enumerate(lines[:10], 1):\n",
    "    print(f\"Line {i}: {line.strip()[:100]}...\")\n",
    "print(f\"Total lines in file: {len(lines)}\")"
   ],
   "id": "2e05dfaa6eff9ad",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 lines of the file:\n",
      "Line 1: [...\n",
      "Line 2: {...\n",
      "Line 3: \"input\": \"CV section: Financial Accountant specializing in financial planning, reporting, and analys...\n",
      "Line 4: \"output\": \"Please give a brief introduction about yourself based on your CV.\"...\n",
      "Line 5: },...\n",
      "Line 6: {...\n",
      "Line 7: \"input\": \"CV section: Associate in Accounting, Northern Maine Community College, 1994, GPA: 3.41; At...\n",
      "Line 8: \"output\": \"What educational qualifications do you have in accounting?\"...\n",
      "Line 9: },...\n",
      "Line 10: {...\n",
      "Total lines in file: 10171\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T04:42:08.334144Z",
     "start_time": "2025-07-26T04:42:08.329395Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "data = []\n",
    "try:\n",
    "    with open('converted_dataset_clean.json', 'r') as file:\n",
    "        data = json.load(file)\n",
    "    print(f\"Total entries parsed: {len(data)}\")\n",
    "    print(\"First 5 entries:\", data[:5])\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"Error parsing as single JSON: {e}\")"
   ],
   "id": "99419bf2db130e85",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries parsed: 2541\n",
      "First 5 entries: [{'input': 'CV section: Financial Accountant specializing in financial planning, reporting, and analysis within the Department of Defense.', 'output': 'Please give a brief introduction about yourself based on your CV.'}, {'input': 'CV section: Associate in Accounting, Northern Maine Community College, 1994, GPA: 3.41; Attended Hudson College, major in Accounting, 78 semester hours toward Bachelor’s degree; Professional Military Comptroller School, 6 weeks, 1998; Certified Defense Financial Manager, CDFM, May 2005.', 'output': 'What educational qualifications do you have in accounting?'}, {'input': 'Question: What educational qualifications do you have in accounting?\\nAnswer: I have an Associate in Accounting from Northern Maine Community College with a GPA of 3.41, 78 semester hours toward a Bachelor’s in Accounting from Hudson College, and a Certified Defense Financial Manager certification from 2005.', 'label': 'correct'}, {'input': 'Question: What educational qualifications do you have in accounting?\\nAnswer: I have a Master’s in Accounting from Hudson College and a CPA certification.', 'label': 'incorrect'}, {'input': 'CV section: Associate in Accounting, Northern Maine Community College, 1994, GPA: 3.41; Attended Hudson College, major in Accounting, 78 semester hours toward Bachelor’s degree; Professional Military Comptroller School, 6 weeks, 1998; Certified Defense Financial Manager, CDFM, May 2005.', 'output': 'How did your training at the Professional Military Comptroller School enhance your skills as a Financial Accountant?'}]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T04:42:10.323463Z",
     "start_time": "2025-07-26T04:42:10.317680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "classification_data = []\n",
    "for entry in data:\n",
    "    if isinstance(entry, dict) and \"input\" in entry and \"label\" in entry:\n",
    "        if \"Question:\" in entry[\"input\"] and \"Answer:\" in entry[\"input\"]:\n",
    "            input_text = entry[\"input\"]\n",
    "            label = 1 if entry[\"label\"] == \"correct\" else 0\n",
    "            classification_data.append({\"text\": input_text, \"label\": label})\n",
    "print(f\"Classification entries found: {len(classification_data)}\")\n",
    "if len(classification_data) == 0:\n",
    "    print(\"No classification entries found. Printing sample entries for debugging:\")\n",
    "    print(data[:10])\n",
    "    raise ValueError(\"No valid classification entries found.\")\n",
    "train_data, val_data = train_test_split(classification_data, test_size=0.2, random_state=42)\n",
    "print(f\"Training entries: {len(train_data)}, Validation entries: {len(val_data)}\")\n",
    "\n",
    "# Check class balance\n",
    "from collections import Counter\n",
    "labels = [entry[\"label\"] for entry in classification_data]\n",
    "print(\"Label distribution:\", Counter(labels))"
   ],
   "id": "c1cd74ce77a10d04",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification entries found: 1680\n",
      "Training entries: 1344, Validation entries: 336\n",
      "Label distribution: Counter({1: 840, 0: 840})\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T04:42:13.895327Z",
     "start_time": "2025-07-26T04:42:12.042067Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import BertTokenizer\n",
    "from datasets import Dataset\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding=\"max_length\", truncation=True, max_length=512)\n",
    "train_dataset = Dataset.from_list(train_data)\n",
    "val_dataset = Dataset.from_list(val_data)\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_val = val_dataset.map(tokenize_function, batched=True)\n",
    "print(f\"Training dataset size: {len(tokenized_train)}\")\n",
    "print(f\"Validation dataset size: {len(tokenized_val)}\")"
   ],
   "id": "9de00572459b25a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/1344 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5ef393f1879048babb09f56edfe69d67"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/336 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5a24e2dd71524440a4390f05da6b9b56"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 1344\n",
      "Validation dataset size: 336\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T04:42:16.549768Z",
     "start_time": "2025-07-26T04:42:15.367551Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip3 install torch torchvision torchaudio\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"MPS available: {torch.backends.mps.is_available()}\")"
   ],
   "id": "e73c8ad4161bca46",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (2.7.1)\r\n",
      "Requirement already satisfied: torchvision in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (0.22.1)\r\n",
      "Requirement already satisfied: torchaudio in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (2.7.1)\r\n",
      "Requirement already satisfied: filelock in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from torch) (3.18.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from torch) (4.14.0)\r\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from torch) (1.14.0)\r\n",
      "Requirement already satisfied: networkx in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from torch) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from torch) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from torch) (2025.3.0)\r\n",
      "Requirement already satisfied: numpy in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from torchvision) (2.2.6)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from torchvision) (11.3.0)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\r\n",
      "\u001B[33mWARNING: There was an error checking the latest version of pip.\u001B[0m\u001B[33m\r\n",
      "\u001B[0mPyTorch version: 2.7.1\n",
      "MPS available: True\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T04:42:20.022369Z",
     "start_time": "2025-07-26T04:42:18.828348Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip3 install ipywidgets\n",
    "import ipywidgets\n",
    "print(f\"ipywidgets version: {ipywidgets.__version__}\")"
   ],
   "id": "eb6c2bbd473c06b8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (8.1.7)\r\n",
      "Requirement already satisfied: comm>=0.1.3 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from ipywidgets) (0.2.2)\r\n",
      "Requirement already satisfied: ipython>=6.1.0 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from ipywidgets) (8.37.0)\r\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from ipywidgets) (5.14.3)\r\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from ipywidgets) (4.0.14)\r\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from ipywidgets) (3.0.15)\r\n",
      "Requirement already satisfied: decorator in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\r\n",
      "Requirement already satisfied: exceptiongroup in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (1.3.0)\r\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\r\n",
      "Requirement already satisfied: matplotlib-inline in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\r\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\r\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.51)\r\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.2)\r\n",
      "Requirement already satisfied: stack_data in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\r\n",
      "Requirement already satisfied: typing_extensions>=4.6 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.14.0)\r\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\r\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\r\n",
      "Requirement already satisfied: wcwidth in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\r\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\r\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\r\n",
      "Requirement already satisfied: pure-eval in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\r\n",
      "\u001B[33mWARNING: There was an error checking the latest version of pip.\u001B[0m\u001B[33m\r\n",
      "\u001B[0mipywidgets version: 8.1.7\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T04:42:30.064504Z",
     "start_time": "2025-07-26T04:42:28.103167Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer\n",
    "from datasets import Dataset\n",
    "\n",
    "# Parse data\n",
    "with open('converted_dataset_clean.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "print(f\"Total entries parsed: {len(data)}\")\n",
    "\n",
    "# Filter classification entries\n",
    "classification_data = []\n",
    "for entry in data:\n",
    "    if isinstance(entry, dict) and \"input\" in entry and \"label\" in entry:\n",
    "        if \"Question:\" in entry[\"input\"] and \"Answer:\" in entry[\"input\"]:\n",
    "            input_text = entry[\"input\"]\n",
    "            label = 1 if entry[\"label\"] == \"correct\" else 0\n",
    "            classification_data.append({\"text\": input_text, \"label\": label})\n",
    "print(f\"Classification entries found: {len(classification_data)}\")\n",
    "if len(classification_data) == 0:\n",
    "    print(\"No classification entries found. Printing sample entries:\")\n",
    "    print(data[:10])\n",
    "    raise ValueError(\"No valid classification entries found.\")\n",
    "\n",
    "# Split data\n",
    "train_data, val_data = train_test_split(classification_data, test_size=0.2, random_state=42)\n",
    "print(f\"Training entries: {len(train_data)}, Validation entries: {len(val_data)}\")\n",
    "\n",
    "# Check class balance\n",
    "from collections import Counter\n",
    "labels = [entry[\"label\"] for entry in classification_data]\n",
    "print(\"Label distribution:\", Counter(labels))\n",
    "\n",
    "# Tokenize\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding=\"max_length\", truncation=True, max_length=512)\n",
    "train_dataset = Dataset.from_list(train_data)\n",
    "val_dataset = Dataset.from_list(val_data)\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_val = val_dataset.map(tokenize_function, batched=True)\n",
    "print(f\"Training dataset size: {len(tokenized_train)}\")\n",
    "print(f\"Validation dataset size: {len(tokenized_val)}\")"
   ],
   "id": "fb1ff2c383359a19",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries parsed: 2541\n",
      "Classification entries found: 1680\n",
      "Training entries: 1344, Validation entries: 336\n",
      "Label distribution: Counter({1: 840, 0: 840})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/1344 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "31c3f9fb678e4d87be369b248b026fae"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/336 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e1272b017b86443697f4330a832c3410"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 1344\n",
      "Validation dataset size: 336\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T04:42:31.899836Z",
     "start_time": "2025-07-26T04:42:31.897819Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "print(sys.executable)  # Should be /Library/Frameworks/Python.framework/Versions/3.13/bin/python3.13"
   ],
   "id": "560250c78e4271d7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/bin/python\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T04:42:48.118691Z",
     "start_time": "2025-07-26T04:42:46.929305Z"
    }
   },
   "cell_type": "code",
   "source": "!pip3 install torch torchvision torchaudio\n",
   "id": "1a1e68121ce09052",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (2.7.1)\r\n",
      "Requirement already satisfied: torchvision in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (0.22.1)\r\n",
      "Requirement already satisfied: torchaudio in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (2.7.1)\r\n",
      "Requirement already satisfied: filelock in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from torch) (3.18.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from torch) (4.14.0)\r\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from torch) (1.14.0)\r\n",
      "Requirement already satisfied: networkx in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from torch) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from torch) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from torch) (2025.3.0)\r\n",
      "Requirement already satisfied: numpy in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from torchvision) (2.2.6)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from torchvision) (11.3.0)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\r\n",
      "\u001B[33mWARNING: There was an error checking the latest version of pip.\u001B[0m\u001B[33m\r\n",
      "\u001B[0m"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T04:42:50.486816Z",
     "start_time": "2025-07-26T04:42:49.093647Z"
    }
   },
   "cell_type": "code",
   "source": "!pip3 install --upgrade transformers\n",
   "id": "964e737d2c9f7f07",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (4.54.0)\r\n",
      "Requirement already satisfied: filelock in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from transformers) (3.18.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from transformers) (0.34.1)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from transformers) (2.2.6)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from transformers) (25.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from transformers) (6.0.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from transformers) (2024.11.6)\r\n",
      "Requirement already satisfied: requests in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from transformers) (2.32.4)\r\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from transformers) (0.21.2)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from transformers) (0.5.3)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from transformers) (4.67.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.14.0)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.5)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from requests->transformers) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from requests->transformers) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from requests->transformers) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from requests->transformers) (2025.7.14)\r\n",
      "\u001B[33mWARNING: There was an error checking the latest version of pip.\u001B[0m\u001B[33m\r\n",
      "\u001B[0m"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T04:42:53.629458Z",
     "start_time": "2025-07-26T04:42:52.237472Z"
    }
   },
   "cell_type": "code",
   "source": "!pip3 install --upgrade accelerate",
   "id": "fc433882588acca6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (1.9.0)\r\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from accelerate) (2.2.6)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from accelerate) (25.0)\r\n",
      "Requirement already satisfied: psutil in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from accelerate) (7.0.0)\r\n",
      "Requirement already satisfied: pyyaml in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from accelerate) (6.0.2)\r\n",
      "Requirement already satisfied: torch>=2.0.0 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from accelerate) (2.7.1)\r\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from accelerate) (0.34.1)\r\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from accelerate) (0.5.3)\r\n",
      "Requirement already satisfied: filelock in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (3.18.0)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (2025.3.0)\r\n",
      "Requirement already satisfied: requests in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.4)\r\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.14.0)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate) (1.1.5)\r\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\r\n",
      "Requirement already satisfied: networkx in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.4.2)\r\n",
      "Requirement already satisfied: jinja2 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.7.14)\r\n",
      "\u001B[33mWARNING: There was an error checking the latest version of pip.\u001B[0m\u001B[33m\r\n",
      "\u001B[0m"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import time\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load accuracy metric\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "# Initialize model\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "model.to(device)\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=2e-5,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train with timing\n",
    "start_time = time.time()\n",
    "trainer.train()\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "print(f\"Total training time: {training_time // 60:.0f} minutes {training_time % 60:.2f} seconds\")"
   ],
   "id": "b41c33e859ab6408",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T04:42:57.502956Z",
     "start_time": "2025-07-26T04:42:57.484016Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[27], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m eval_results \u001B[38;5;241m=\u001B[39m \u001B[43mtrainer\u001B[49m\u001B[38;5;241m.\u001B[39mevaluate()\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFinal Evaluation Results:\u001B[39m\u001B[38;5;124m\"\u001B[39m, eval_results)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "execution_count": 27,
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(\"Final Evaluation Results:\", eval_results)"
   ],
   "id": "c33d4b9899cb550c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "log_history = trainer.state.log_history\n",
    "val_accuracy = []\n",
    "epochs = []\n",
    "for log in log_history:\n",
    "    if 'eval_accuracy' in log and 'epoch' in log:\n",
    "        val_accuracy.append(log['eval_accuracy'])\n",
    "        epochs.append(log['epoch'])\n",
    "print(\"Epochs:\", epochs)\n",
    "print(\"Validation Accuracy:\", val_accuracy)"
   ],
   "id": "987ec7bccab7776d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model.save_pretrained('./trained_model')\n",
    "tokenizer.save_pretrained('./trained_model')\n",
    "import shutil\n",
    "shutil.make_archive('trained_model', 'zip', './trained_model')\n",
    "from IPython.display import FileLink\n",
    "display(FileLink('trained_model.zip'))"
   ],
   "id": "ef6abe2eb86d0d93",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T16:50:53.806991Z",
     "start_time": "2025-07-23T16:50:53.374008Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import Counter\n",
    "try:\n",
    "    train_labels = [entry[\"label\"] for entry in tokenized_train]\n",
    "    val_labels = [entry[\"label\"] for entry in tokenized_val]\n",
    "    print(\"Training label distribution:\", Counter(train_labels))\n",
    "    print(\"Validation label distribution:\", Counter(val_labels))\n",
    "except NameError:\n",
    "    print(\"Tokenized datasets not defined. Re-run tokenization (Step 3).\")"
   ],
   "id": "418e78cd1a68e6f7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training label distribution: Counter({0: 675, 1: 669})\n",
      "Validation label distribution: Counter({1: 171, 0: 165})\n"
     ]
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T16:50:55.373574Z",
     "start_time": "2025-07-23T16:50:55.367658Z"
    }
   },
   "cell_type": "code",
   "source": [
    "try:\n",
    "    print(\"Sample training entry:\", tokenized_train[0])\n",
    "    print(\"Sample validation entry:\", tokenized_val[0])\n",
    "except NameError:\n",
    "    print(\"Tokenized datasets not defined. Re-run tokenization (Step 3).\")"
   ],
   "id": "7ad771f3c8da71ef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample training entry: {'text': 'Question: Can you describe how you supported NASA mission-based reporting activities and the skills you applied?\\nAnswer: I delegated reporting tasks to others without direct involvement.', 'label': 0, 'input_ids': [101, 3160, 1024, 2064, 2017, 6235, 2129, 2017, 3569, 9274, 3260, 1011, 2241, 7316, 3450, 1998, 1996, 4813, 2017, 4162, 1029, 3437, 1024, 1045, 11849, 2094, 7316, 8518, 2000, 2500, 2302, 3622, 6624, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "Sample validation entry: {'text': 'Question: How did you overhaul MySQL schema indexation at McKesson?\\nAnswer: I avoided MySQL optimizations.', 'label': 0, 'input_ids': [101, 3160, 1024, 2129, 2106, 2017, 18181, 2026, 2015, 4160, 2140, 8040, 28433, 5950, 3370, 2012, 11338, 9681, 3385, 1029, 3437, 1024, 1045, 9511, 2026, 2015, 4160, 2140, 20600, 2015, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T16:50:58.968489Z",
     "start_time": "2025-07-23T16:50:57.068852Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer\n",
    "from datasets import Dataset\n",
    "\n",
    "# Parse data\n",
    "with open('converted_dataset_clean.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "print(f\"Total entries parsed: {len(data)}\")\n",
    "\n",
    "# Filter classification entries\n",
    "classification_data = []\n",
    "for entry in data:\n",
    "    if isinstance(entry, dict) and \"input\" in entry and \"label\" in entry:\n",
    "        if \"Question:\" in entry[\"input\"] and \"Answer:\" in entry[\"input\"]:\n",
    "            input_text = entry[\"input\"]\n",
    "            label = 1 if entry[\"label\"] == \"correct\" else 0\n",
    "            classification_data.append({\"text\": input_text, \"label\": label})\n",
    "print(f\"Classification entries found: {len(classification_data)}\")\n",
    "if len(classification_data) == 0:\n",
    "    print(\"No classification entries found. Printing sample entries:\")\n",
    "    print(data[:10])\n",
    "    raise ValueError(\"No valid classification entries found.\")\n",
    "\n",
    "# Split data\n",
    "train_data, val_data = train_test_split(classification_data, test_size=0.2, random_state=42)\n",
    "print(f\"Training entries: {len(train_data)}, Validation entries: {len(val_data)}\")\n",
    "\n",
    "# Check class balance\n",
    "from collections import Counter\n",
    "labels = [entry[\"label\"] for entry in classification_data]\n",
    "print(\"Label distribution:\", Counter(labels))\n",
    "\n",
    "# Tokenize\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding=\"max_length\", truncation=True, max_length=512)\n",
    "train_dataset = Dataset.from_list(train_data)\n",
    "val_dataset = Dataset.from_list(val_data)\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_val = val_dataset.map(tokenize_function, batched=True)\n",
    "print(f\"Training dataset size: {len(tokenized_train)}\")\n",
    "print(f\"Validation dataset size: {len(tokenized_val)}\")"
   ],
   "id": "9401c61a971cd52",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries parsed: 2541\n",
      "Classification entries found: 1680\n",
      "Training entries: 1344, Validation entries: 336\n",
      "Label distribution: Counter({1: 840, 0: 840})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.txt from cache at /Users/dasunsathsara/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/vocab.txt\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /Users/dasunsathsara/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/tokenizer_config.json\n",
      "loading file tokenizer.json from cache at /Users/dasunsathsara/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/tokenizer.json\n",
      "loading file chat_template.jinja from cache at None\n",
      "loading configuration file config.json from cache at /Users/dasunsathsara/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.53.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/1344 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e12a3880d8c242b991c3bd84e46751e7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/336 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c01669996b5643a1b05c5a91de655814"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 1344\n",
      "Validation dataset size: 336\n"
     ]
    }
   ],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T23:17:02.132267Z",
     "start_time": "2025-07-23T20:04:57.239987Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import time\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load accuracy metric\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "# Compute class weights\n",
    "try:\n",
    "    train_labels = [entry[\"label\"] for entry in tokenized_train]\n",
    "    class_weights = compute_class_weight('balanced', classes=np.array([0, 1]), y=train_labels)\n",
    "    class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "    print(\"Class weights:\", class_weights)\n",
    "except NameError:\n",
    "    print(\"Tokenized datasets not defined. Run Step 2.\")\n",
    "    raise\n",
    "\n",
    "# Custom Trainer for class weights\n",
    "class WeightedTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        loss_fct = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "# Initialize model\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "model.to(device)\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=20,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=1e-5,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    ")\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = WeightedTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train with timing\n",
    "start_time = time.time()\n",
    "trainer.train()\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "print(f\"Total training time: {training_time // 60:.0f} minutes {training_time % 60:.2f} seconds\")"
   ],
   "id": "59923c5e90e35797",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Class weights: tensor([0.9956, 1.0045], device='mps:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /Users/dasunsathsara/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.53.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /Users/dasunsathsara/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/model.safetensors\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "The following columns in the Training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 1,344\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3,360\n",
      "  Number of trainable parameters = 109,483,778\n",
      "/Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3360' max='3360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3360/3360 3:11:47, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.108000</td>\n",
       "      <td>0.058570</td>\n",
       "      <td>0.979167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.078400</td>\n",
       "      <td>0.014393</td>\n",
       "      <td>0.991071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.079613</td>\n",
       "      <td>0.988095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.059600</td>\n",
       "      <td>0.094478</td>\n",
       "      <td>0.982143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.042178</td>\n",
       "      <td>0.991071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.081808</td>\n",
       "      <td>0.988095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.118196</td>\n",
       "      <td>0.985119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.112763</td>\n",
       "      <td>0.985119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.125487</td>\n",
       "      <td>0.985119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.128001</td>\n",
       "      <td>0.985119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.129622</td>\n",
       "      <td>0.985119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.130686</td>\n",
       "      <td>0.985119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.131081</td>\n",
       "      <td>0.985119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.129781</td>\n",
       "      <td>0.985119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.132473</td>\n",
       "      <td>0.985119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.134040</td>\n",
       "      <td>0.985119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.135674</td>\n",
       "      <td>0.985119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.129636</td>\n",
       "      <td>0.985119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.132498</td>\n",
       "      <td>0.985119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.132760</td>\n",
       "      <td>0.985119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the Evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 336\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/checkpoint-168\n",
      "Configuration saved in ./results/checkpoint-168/config.json\n",
      "Model weights saved in ./results/checkpoint-168/model.safetensors\n",
      "/Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "The following columns in the Evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 336\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/checkpoint-336\n",
      "Configuration saved in ./results/checkpoint-336/config.json\n",
      "Model weights saved in ./results/checkpoint-336/model.safetensors\n",
      "/Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "The following columns in the Evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 336\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/checkpoint-504\n",
      "Configuration saved in ./results/checkpoint-504/config.json\n",
      "Model weights saved in ./results/checkpoint-504/model.safetensors\n",
      "/Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "The following columns in the Evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 336\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/checkpoint-672\n",
      "Configuration saved in ./results/checkpoint-672/config.json\n",
      "Model weights saved in ./results/checkpoint-672/model.safetensors\n",
      "/Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "The following columns in the Evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 336\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/checkpoint-840\n",
      "Configuration saved in ./results/checkpoint-840/config.json\n",
      "Model weights saved in ./results/checkpoint-840/model.safetensors\n",
      "/Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "The following columns in the Evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 336\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/checkpoint-1008\n",
      "Configuration saved in ./results/checkpoint-1008/config.json\n",
      "Model weights saved in ./results/checkpoint-1008/model.safetensors\n",
      "/Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "The following columns in the Evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 336\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/checkpoint-1176\n",
      "Configuration saved in ./results/checkpoint-1176/config.json\n",
      "Model weights saved in ./results/checkpoint-1176/model.safetensors\n",
      "/Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "The following columns in the Evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 336\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/checkpoint-1344\n",
      "Configuration saved in ./results/checkpoint-1344/config.json\n",
      "Model weights saved in ./results/checkpoint-1344/model.safetensors\n",
      "/Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "The following columns in the Evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 336\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/checkpoint-1512\n",
      "Configuration saved in ./results/checkpoint-1512/config.json\n",
      "Model weights saved in ./results/checkpoint-1512/model.safetensors\n",
      "/Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "The following columns in the Evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 336\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/checkpoint-1680\n",
      "Configuration saved in ./results/checkpoint-1680/config.json\n",
      "Model weights saved in ./results/checkpoint-1680/model.safetensors\n",
      "/Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "The following columns in the Evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 336\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/checkpoint-1848\n",
      "Configuration saved in ./results/checkpoint-1848/config.json\n",
      "Model weights saved in ./results/checkpoint-1848/model.safetensors\n",
      "/Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "The following columns in the Evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 336\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/checkpoint-2016\n",
      "Configuration saved in ./results/checkpoint-2016/config.json\n",
      "Model weights saved in ./results/checkpoint-2016/model.safetensors\n",
      "/Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "The following columns in the Evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 336\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/checkpoint-2184\n",
      "Configuration saved in ./results/checkpoint-2184/config.json\n",
      "Model weights saved in ./results/checkpoint-2184/model.safetensors\n",
      "/Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "The following columns in the Evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 336\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/checkpoint-2352\n",
      "Configuration saved in ./results/checkpoint-2352/config.json\n",
      "Model weights saved in ./results/checkpoint-2352/model.safetensors\n",
      "/Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "The following columns in the Evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 336\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/checkpoint-2520\n",
      "Configuration saved in ./results/checkpoint-2520/config.json\n",
      "Model weights saved in ./results/checkpoint-2520/model.safetensors\n",
      "/Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "The following columns in the Evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 336\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/checkpoint-2688\n",
      "Configuration saved in ./results/checkpoint-2688/config.json\n",
      "Model weights saved in ./results/checkpoint-2688/model.safetensors\n",
      "/Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "The following columns in the Evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 336\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/checkpoint-2856\n",
      "Configuration saved in ./results/checkpoint-2856/config.json\n",
      "Model weights saved in ./results/checkpoint-2856/model.safetensors\n",
      "/Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "The following columns in the Evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 336\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/checkpoint-3024\n",
      "Configuration saved in ./results/checkpoint-3024/config.json\n",
      "Model weights saved in ./results/checkpoint-3024/model.safetensors\n",
      "/Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "The following columns in the Evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 336\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/checkpoint-3192\n",
      "Configuration saved in ./results/checkpoint-3192/config.json\n",
      "Model weights saved in ./results/checkpoint-3192/model.safetensors\n",
      "/Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "The following columns in the Evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 336\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./results/checkpoint-3360\n",
      "Configuration saved in ./results/checkpoint-3360/config.json\n",
      "Model weights saved in ./results/checkpoint-3360/model.safetensors\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./results/checkpoint-336 (score: 0.9910714285714286).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training time: 191 minutes 57.92 seconds\n"
     ]
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T02:25:34.568221Z",
     "start_time": "2025-07-24T02:24:54.579575Z"
    }
   },
   "cell_type": "code",
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(\"Final Evaluation Results:\", eval_results)"
   ],
   "id": "3b4e79ca9c4774ca",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the Evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 336\n",
      "  Batch size = 8\n",
      "/Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='84' max='42' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42/42 05:55]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Evaluation Results: {'eval_loss': 0.014393378980457783, 'eval_accuracy': 0.9910714285714286, 'eval_runtime': 39.8831, 'eval_samples_per_second': 8.425, 'eval_steps_per_second': 1.053, 'epoch': 20.0}\n"
     ]
    }
   ],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T02:25:55.718170Z",
     "start_time": "2025-07-24T02:25:55.711244Z"
    }
   },
   "cell_type": "code",
   "source": [
    "log_history = trainer.state.log_history\n",
    "val_accuracy = []\n",
    "epochs = []\n",
    "for log in log_history:\n",
    "    if 'eval_accuracy' in log and 'epoch' in log:\n",
    "        val_accuracy.append(log['eval_accuracy'])\n",
    "        epochs.append(log['epoch'])\n",
    "print(\"Epochs:\", epochs)\n",
    "print(\"Validation Accuracy:\", val_accuracy)"
   ],
   "id": "55359fec3ef69386",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 20.0]\n",
      "Validation Accuracy: [0.9791666666666666, 0.9910714285714286, 0.9880952380952381, 0.9821428571428571, 0.9910714285714286, 0.9880952380952381, 0.9851190476190477, 0.9851190476190477, 0.9851190476190477, 0.9851190476190477, 0.9851190476190477, 0.9851190476190477, 0.9851190476190477, 0.9851190476190477, 0.9851190476190477, 0.9851190476190477, 0.9851190476190477, 0.9851190476190477, 0.9851190476190477, 0.9851190476190477, 0.9910714285714286]\n"
     ]
    }
   ],
   "execution_count": 74
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T02:26:48.571917Z",
     "start_time": "2025-07-24T02:26:32.034911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.save_pretrained('./trained_model')\n",
    "tokenizer.save_pretrained('./trained_model')\n",
    "import shutil\n",
    "shutil.make_archive('trained_model', 'zip', './trained_model')\n",
    "from IPython.display import FileLink\n",
    "display(FileLink('trained_model.zip'))"
   ],
   "id": "aa46940e67c2c8f8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./trained_model/config.json\n",
      "Model weights saved in ./trained_model/model.safetensors\n",
      "tokenizer config file saved in ./trained_model/tokenizer_config.json\n",
      "Special tokens file saved in ./trained_model/special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "/Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/app/trained_model.zip"
      ],
      "text/html": [
       "<a href='trained_model.zip' target='_blank'>trained_model.zip</a><br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 75
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T02:30:13.825842Z",
     "start_time": "2025-07-24T02:30:11.620275Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer\n",
    "from datasets import Dataset\n",
    "\n",
    "# Parse data\n",
    "with open('converted_dataset_clean.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "print(f\"Total entries parsed: {len(data)}\")\n",
    "\n",
    "# Filter classification entries\n",
    "classification_data = []\n",
    "for entry in data:\n",
    "    if isinstance(entry, dict) and \"input\" in entry and \"label\" in entry:\n",
    "        if \"Question:\" in entry[\"input\"] and \"Answer:\" in entry[\"input\"]:\n",
    "            input_text = entry[\"input\"]\n",
    "            label = 1 if entry[\"label\"] == \"correct\" else 0\n",
    "            classification_data.append({\"text\": input_text, \"label\": label})\n",
    "print(f\"Classification entries found: {len(classification_data)}\")\n",
    "\n",
    "# Split data\n",
    "train_data, val_data = train_test_split(classification_data, test_size=0.2, random_state=42)\n",
    "print(f\"Training entries: {len(train_data)}, Validation entries: {len(val_data)}\")\n",
    "\n",
    "# Check class balance\n",
    "from collections import Counter\n",
    "labels = [entry[\"label\"] for entry in classification_data]\n",
    "print(\"Label distribution:\", Counter(labels))\n",
    "\n",
    "# Tokenize\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding=\"max_length\", truncation=True, max_length=512)\n",
    "train_dataset = Dataset.from_list(train_data)\n",
    "val_dataset = Dataset.from_list(val_data)\n",
    "tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_val = val_dataset.map(tokenize_function, batched=True)\n",
    "print(f\"Training dataset size: {len(tokenized_train)}\")\n",
    "print(f\"Validation dataset size: {len(tokenized_val)}\")"
   ],
   "id": "4506c48d9b9b25b8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries parsed: 2541\n",
      "Classification entries found: 1680\n",
      "Training entries: 1344, Validation entries: 336\n",
      "Label distribution: Counter({1: 840, 0: 840})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.txt from cache at /Users/dasunsathsara/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/vocab.txt\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /Users/dasunsathsara/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/tokenizer_config.json\n",
      "loading file tokenizer.json from cache at /Users/dasunsathsara/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/tokenizer.json\n",
      "loading file chat_template.jinja from cache at None\n",
      "loading configuration file config.json from cache at /Users/dasunsathsara/.cache/huggingface/hub/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594/config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.53.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/1344 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d99ab86011364a12ad324e440d7d6356"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/336 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a874aaac08b840c3b395bb4d2ead9c58"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset size: 1344\n",
      "Validation dataset size: 336\n"
     ]
    }
   ],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-24T02:30:58.263537Z",
     "start_time": "2025-07-24T02:30:23.551495Z"
    }
   },
   "cell_type": "code",
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(\"Final Evaluation Results:\", eval_results)"
   ],
   "id": "d6120abcde486a41",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the Evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: text. If text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 336\n",
      "  Batch size = 8\n",
      "/Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "2025-07-24 08:00:33.358 Python[91780:17791060] Error creating directory \n",
      " The volume ‚ÄúMacintosh HD‚Äù is out of space. You can‚Äôt save the file ‚Äúmpsgraph-91780-2025-07-24_08_00_31-3963895706‚Äù because the volume ‚ÄúMacintosh HD‚Äù is out of space.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Evaluation Results: {'eval_loss': 0.014393378980457783, 'eval_accuracy': 0.9910714285714286, 'eval_runtime': 34.699, 'eval_samples_per_second': 9.683, 'eval_steps_per_second': 1.21, 'epoch': 20.0}\n"
     ]
    }
   ],
   "execution_count": 78
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T04:43:21.602032Z",
     "start_time": "2025-07-26T04:43:21.291666Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer\n",
    "from datasets import Dataset\n",
    "\n",
    "# Load data\n",
    "with open('converted_dataset_clean.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "print(f\"Total entries parsed: {len(data)}\")\n",
    "\n",
    "# Filter classification entries\n",
    "classification_data = []\n",
    "for entry in data:\n",
    "    if isinstance(entry, dict) and \"input\" in entry and \"label\" in entry:\n",
    "        if \"Question:\" in entry[\"input\"] and \"Answer:\" in entry[\"input\"]:\n",
    "            input_text = entry[\"input\"]\n",
    "            label = 1 if entry[\"label\"] == \"correct\" else 0\n",
    "            classification_data.append({\"text\": input_text, \"label\": label})\n",
    "print(f\"Classification entries found: {len(classification_data)}\")\n",
    "\n",
    "# Split into train+val and test (60% train, 20% val, 20% test)\n",
    "train_val_data, test_data = train_test_split(classification_data, test_size=0.2, random_state=42)\n",
    "train_data, val_data = train_test_split(train_val_data, test_size=0.25, random_state=42)  # 0.25 * 0.8 = 0.2\n",
    "print(f\"Training entries: {len(train_data)}, Validation entries: {len(val_data)}, Test entries: {len(test_data)}\")\n",
    "\n",
    "# Tokenize test set\n",
    "tokenizer = BertTokenizer.from_pretrained('./trained_model')\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['text'], padding=\"max_length\", truncation=True, max_length=512)\n",
    "test_dataset = Dataset.from_list(test_data)\n",
    "tokenized_test = test_dataset.map(tokenize_function, batched=True)\n",
    "print(f\"Test dataset size: {len(tokenized_test)}\")"
   ],
   "id": "28839691752feae9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries parsed: 2541\n",
      "Classification entries found: 1680\n",
      "Training entries: 1008, Validation entries: 336, Test entries: 336\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/336 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "acd0bafeb06342dca61ccbd9acab1a45"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset size: 336\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T04:43:36.247827Z",
     "start_time": "2025-07-26T04:43:35.053591Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install seaborn",
   "id": "2dc6119e3dfb6137",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (0.13.2)\r\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from seaborn) (2.2.6)\r\n",
      "Requirement already satisfied: pandas>=1.2 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from seaborn) (2.3.1)\r\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from seaborn) (3.10.3)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.2)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.59.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\r\n",
      "Requirement already satisfied: pillow>=8 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.3.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from pandas>=1.2->seaborn) (2025.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\r\n",
      "\u001B[33mWARNING: There was an error checking the latest version of pip.\u001B[0m\u001B[33m\r\n",
      "\u001B[0m"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T04:43:42.744111Z",
     "start_time": "2025-07-26T04:43:41.721384Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "with open('converted_dataset_clean.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "classification_data = [entry for entry in data if \"label\" in entry and \"Question:\" in entry[\"input\"] and \"Answer:\" in entry[\"input\"]]\n",
    "\n",
    "new_examples = [\n",
    "    {\"input\": \"Question: What was a key collaboration challenge you faced, and how did you address it?\\nAnswer: I used Docker to streamline team workflows.\", \"label\": \"correct\"},\n",
    "    {\"input\": \"Question: How do you integrate backend APIs with front-end?\\nAnswer: I used Spring Boot with React for integration.\", \"label\": \"correct\"},\n",
    "    {\"input\": \"Question: How did you improve debugging efficiency?\\nAnswer: I used automated testing with Selenium.\", \"label\": \"correct\"},\n",
    "    {\"input\": \"Question: What was a key collaboration challenge you faced, and how did you address it?\\nAnswer: I ignored team issues.\", \"label\": \"incorrect\"},\n",
    "    {\"input\": \"Question: How do you integrate backend APIs with front-end?\\nAnswer: I avoided API integration.\", \"label\": \"incorrect\"},\n",
    "    {\"input\": \"Question: How did you improve debugging efficiency?\\nAnswer: I didn’t use debugging tools.\", \"label\": \"incorrect\"},\n",
    "    # Add the new examples here\n",
    "    {\"input\": \"Question: How did you optimize database performance at your job?\\nAnswer: I optimized PostgreSQL queries, reducing response times by 15%.\", \"label\": \"correct\"},\n",
    "    {\"input\": \"Question: How did you optimize database performance at your job?\\nAnswer: I ignored database optimization.\", \"label\": \"incorrect\"},\n",
    "    {\"input\": \"Question: What tools did you use for version control?\\nAnswer: I implemented Git to manage code versions effectively.\", \"label\": \"correct\"},\n",
    "    {\"input\": \"Question: What tools did you use for version control?\\nAnswer: I used manual file tracking instead of version control.\", \"label\": \"incorrect\"},\n",
    "    {\"input\": \"Question: How did you improve application scalability?\\nAnswer: I deployed applications using AWS Elastic Beanstalk.\", \"label\": \"correct\"},\n",
    "    {\"input\": \"Question: How did you improve application scalability?\\nAnswer: I avoided scalability enhancements.\", \"label\": \"incorrect\"},\n",
    "    {\"input\": \"Question: How did you manage financial reporting challenges?\\nAnswer: I automated financial reports using Excel macros.\", \"label\": \"correct\"},\n",
    "    {\"input\": \"Question: How did you manage financial reporting challenges?\\nAnswer: I relied on manual reporting without automation.\", \"label\": \"incorrect\"},\n",
    "    {\"input\": \"Question: What strategies did you use to reduce budget variances?\\nAnswer: I implemented variance analysis with SAP software.\", \"label\": \"correct\"},\n",
    "    {\"input\": \"Question: What strategies did you use to reduce budget variances?\\nAnswer: I ignored budget variance issues.\", \"label\": \"incorrect\"},\n",
    "    {\"input\": \"Question: How did you ensure specimen integrity during collection?\\nAnswer: I followed OSHA guidelines for aseptic techniques.\", \"label\": \"correct\"},\n",
    "    {\"input\": \"Question: How did you ensure specimen integrity during collection?\\nAnswer: I skipped proper collection protocols.\", \"label\": \"incorrect\"},\n",
    "    {\"input\": \"Question: What methods did you use to train new phlebotomists?\\nAnswer: I conducted hands-on training with HIPAA compliance.\", \"label\": \"correct\"},\n",
    "    {\"input\": \"Question: What methods did you use to train new phlebotomists?\\nAnswer: I provided no formal training.\", \"label\": \"incorrect\"},\n",
    "    {\"input\": \"Question: How did you enhance user interface performance?\\nAnswer: I optimized CSS and JavaScript for faster rendering.\", \"label\": \"correct\"},\n",
    "    {\"input\": \"Question: How did you enhance user interface performance?\\nAnswer: I used unoptimized code without improvements.\", \"label\": \"incorrect\"},\n",
    "    {\"input\": \"Question: What approach did you take for cloud migration?\\nAnswer: I used Azure to migrate workloads with zero downtime.\", \"label\": \"correct\"},\n",
    "    {\"input\": \"Question: What approach did you take for cloud migration?\\nAnswer: I avoided cloud migration entirely.\", \"label\": \"incorrect\"}\n",
    "]\n",
    "\n",
    "classification_data.extend(new_examples)\n",
    "\n",
    "# Split dataset\n",
    "train_val_data, test_data = train_test_split(classification_data, test_size=0.2, random_state=42)\n",
    "train_data, val_data = train_test_split(train_val_data, test_size=0.25, random_state=42)\n",
    "print(f\"Training entries: {len(train_data)}, Validation entries: {len(val_data)}, Test entries: {len(test_data)}\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['input'], padding=\"max_length\", truncation=True, max_length=512)\n",
    "tokenized_train = Dataset.from_list(train_data).map(tokenize_function, batched=True)\n",
    "tokenized_val = Dataset.from_list(val_data).map(tokenize_function, batched=True)\n",
    "tokenized_test = Dataset.from_list(test_data).map(tokenize_function, batched=True)\n",
    "\n",
    "# Save updated dataset\n",
    "with open('converted_dataset_clean_updated.json', 'w') as file:\n",
    "    json.dump(classification_data, file, indent=2)"
   ],
   "id": "8f12eb0625af0c95",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training entries: 1022, Validation entries: 341, Test entries: 341\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/1022 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c60c214fe4a1436d855858f9d928ca9b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/341 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3215eb628ae84173ab2cacb7cd690606"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/341 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b4e3b428d813491a82111c58983157a9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T05:01:58.265827Z",
     "start_time": "2025-07-26T05:01:57.241245Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the updated dataset\n",
    "with open('converted_dataset_clean_updated.json', 'r') as file:\n",
    "    classification_data = json.load(file)\n",
    "\n",
    "# Convert string labels to integers\n",
    "for entry in classification_data:\n",
    "    entry[\"label\"] = 1 if entry[\"label\"] == \"correct\" else 0\n",
    "\n",
    "# Split dataset\n",
    "train_val_data, test_data = train_test_split(classification_data, test_size=0.2, random_state=42)\n",
    "train_data, val_data = train_test_split(train_val_data, test_size=0.25, random_state=42)\n",
    "print(f\"Training entries: {len(train_data)}, Validation entries: {len(val_data)}, Test entries: {len(test_data)}\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['input'], padding=\"max_length\", truncation=True, max_length=512)\n",
    "\n",
    "tokenized_train = Dataset.from_list(train_data).map(tokenize_function, batched=True)\n",
    "tokenized_val = Dataset.from_list(val_data).map(tokenize_function, batched=True)\n",
    "tokenized_test = Dataset.from_list(test_data).map(tokenize_function, batched=True)\n",
    "\n",
    "# Save the updated dataset with numeric labels (optional, for future use)\n",
    "with open('converted_dataset_clean_updated_numeric.json', 'w') as file:\n",
    "    json.dump(classification_data, file, indent=2)"
   ],
   "id": "a64455c59ec0eb3e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training entries: 1022, Validation entries: 341, Test entries: 341\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/1022 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0116d8b63ceb49818db4e0431a4f3b3d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/341 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "903a09a5b51145cf9ddd8d0de3a62f06"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/341 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cc6e1b5566d84e41b97f2bad3bd550be"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T07:53:14.490402Z",
     "start_time": "2025-07-26T05:41:03.052796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load model\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2, hidden_dropout_prob=0.2)\n",
    "model.to(device)\n",
    "\n",
    "# Compute class weights\n",
    "train_labels = [example[\"label\"].item() if isinstance(example[\"label\"], torch.Tensor) else example[\"label\"] for example in tokenized_train]\n",
    "class_weights = compute_class_weight('balanced', classes=np.array([0, 1]), y=train_labels)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "# Define compute_metrics function\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = np.argmax(pred.predictions, axis=1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc}\n",
    "\n",
    "# Custom Trainer with weighted loss\n",
    "class WeightedTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.get(\"labels\").to(device)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        loss_fct = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=1e-5,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=500,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",  # This now matches compute_metrics\n",
    "    greater_is_better=True,\n",
    "    dataloader_pin_memory=False\n",
    ")\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = WeightedTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_val,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Train with timing\n",
    "start_time = time.time()\n",
    "trainer.train()\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"\\nTraining completed in {(end_time - start_time):.2f} seconds.\")\n"
   ],
   "id": "5297c8acc217a0a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1280' max='1280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1280/1280 2:12:02, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.042100</td>\n",
       "      <td>0.039562</td>\n",
       "      <td>0.985337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.075778</td>\n",
       "      <td>0.982405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training completed in 7927.43 seconds.\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T08:47:42.116655Z",
     "start_time": "2025-07-26T08:46:38.163692Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Evaluate on test set\n",
    "test_results = trainer.evaluate(eval_dataset=tokenized_test)\n",
    "print(\"Test Set Results:\", test_results)\n",
    "\n",
    "# Detailed metrics (optional)\n",
    "predictions = trainer.predict(tokenized_test)\n",
    "labels = predictions.label_ids\n",
    "preds = np.argmax(predictions.predictions, axis=1)\n",
    "print(f\"Accuracy: {accuracy_score(labels, preds):.4f}\")\n",
    "print(f\"Precision: {precision_score(labels, preds):.4f}\")\n",
    "print(f\"Recall: {recall_score(labels, preds):.4f}\")\n",
    "print(f\"F1 Score: {f1_score(labels, preds):.4f}\")"
   ],
   "id": "26133247100d4891",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Results: {'eval_loss': 0.10536162555217743, 'eval_accuracy': 0.9765395894428153, 'eval_runtime': 41.4419, 'eval_samples_per_second': 8.228, 'eval_steps_per_second': 1.038, 'epoch': 10.0}\n",
      "Accuracy: 0.9765\n",
      "Precision: 0.9811\n",
      "Recall: 0.9689\n",
      "F1 Score: 0.9750\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T08:50:13.009027Z",
     "start_time": "2025-07-26T08:49:55.858636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import shutil\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# Load best model (adjust path if needed)\n",
    "best_checkpoint = './results/checkpoint-*'  # Replace with actual path from training\n",
    "model.save_pretrained('./trained_model_retrained')\n",
    "tokenizer.save_pretrained('./trained_model_retrained')\n",
    "\n",
    "# Create zip for download\n",
    "shutil.make_archive('trained_model_retrained', 'zip', './trained_model_retrained')\n",
    "display(FileLink('trained_model_retrained.zip'))"
   ],
   "id": "18eaefaa90dd93ed",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "/Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/app/trained_model_retrained.zip"
      ],
      "text/html": [
       "<a href='trained_model_retrained.zip' target='_blank'>trained_model_retrained.zip</a><br>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T08:51:27.319835Z",
     "start_time": "2025-07-26T08:51:20.132288Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Load saved model\n",
    "model_path = './trained_model_retrained'\n",
    "model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Example inference\n",
    "text = \"Question: How did you improve debugging efficiency?\\nAnswer: I used IDE tools to streamline debugging.\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "probabilities = torch.softmax(outputs.logits, dim=-1).cpu().numpy()[0]\n",
    "prediction = torch.argmax(outputs.logits, dim=-1).item()\n",
    "print(f\"Input: {text}\")\n",
    "print(f\"Probabilities: P(incorrect)= {probabilities[0]:.4f}, P(correct)= {probabilities[1]:.4f}\")\n",
    "print(f\"Prediction: {'correct' if prediction == 1 else 'incorrect'}\")"
   ],
   "id": "de8612eab04b101d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Question: How did you improve debugging efficiency?\n",
      "Answer: I used IDE tools to streamline debugging.\n",
      "Probabilities: P(incorrect)= 0.0016, P(correct)= 0.9984\n",
      "Prediction: correct\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T09:16:30.657145Z",
     "start_time": "2025-07-26T09:16:21.765767Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "\n",
    "# Load saved model and tokenizer\n",
    "model_path = './trained_model_retrained'\n",
    "model = BertForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_path)\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"Model loaded successfully on {device}\")\n",
    "\n",
    "# Prepare test examples\n",
    "test_examples = [\n",
    "    \"Question: What was a key collaboration challenge you faced at WH Solutions, and how did you address it?\\nAnswer: I faced challenges coordinating with the frontend team due to misaligned APIs, which I resolved by implementing Swagger for better API documentation.\",\n",
    "    \"Question: How do you integrate backend APIs with front-end?\\nAnswer: I use axios to connect React UIs with REST APIs.\",\n",
    "    \"Question: How did you improve debugging efficiency?\\nAnswer: I used IDE tools to streamline debugging.\",\n",
    "    \"Question: What was your role at WH Solutions?\\nAnswer: I was an Intern Software Engineer, working on full-stack application development.\",  # Correct\n",
    "    \"Question: What was your role at WH Solutions?\\nAnswer: I was a project manager overseeing software development.\"  # Incorrect\n",
    "]\n",
    "\n",
    "# Tokenize and batch the data\n",
    "def tokenize_test(examples):\n",
    "    return tokenizer(examples, padding=\"max_length\", truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "\n",
    "tokenized_test = Dataset.from_dict({\"text\": test_examples}).map(lambda x: tokenize_test(x[\"text\"]), batched=True)\n",
    "tokenized_test.set_format('torch', columns=['input_ids', 'attention_mask'])\n",
    "\n",
    "# Move to device\n",
    "inputs = {k: v.to(device) for k, v in tokenized_test[:].items() if k in ['input_ids', 'attention_mask']}"
   ],
   "id": "c08a88db00d746b1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully on mps\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "824a9c143b764b8aab48fdf5d6683db1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 64
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T09:16:42.004158Z",
     "start_time": "2025-07-26T09:16:39.290926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Run inference on the batch\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "probs = torch.softmax(outputs.logits, dim=-1).cpu().numpy()\n",
    "preds = torch.argmax(outputs.logits, dim=-1).cpu().numpy()\n",
    "\n",
    "# Display results\n",
    "for i, (text, prob, pred) in enumerate(zip(test_examples, probs, preds)):\n",
    "    print(f\"Test Case {i + 1}:\")\n",
    "    print(f\"Input: {text}\")\n",
    "    print(f\"Probabilities: P(incorrect)= {prob[0]:.4f}, P(correct)= {prob[1]:.4f}\")\n",
    "    print(f\"Prediction: {'correct' if pred == 1 else 'incorrect'}\\n\")"
   ],
   "id": "4bcb35e6334e648d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Case 1:\n",
      "Input: Question: What was a key collaboration challenge you faced at WH Solutions, and how did you address it?\n",
      "Answer: I faced challenges coordinating with the frontend team due to misaligned APIs, which I resolved by implementing Swagger for better API documentation.\n",
      "Probabilities: P(incorrect)= 0.0027, P(correct)= 0.9973\n",
      "Prediction: correct\n",
      "\n",
      "Test Case 2:\n",
      "Input: Question: How do you integrate backend APIs with front-end?\n",
      "Answer: I use axios to connect React UIs with REST APIs.\n",
      "Probabilities: P(incorrect)= 0.0023, P(correct)= 0.9977\n",
      "Prediction: correct\n",
      "\n",
      "Test Case 3:\n",
      "Input: Question: How did you improve debugging efficiency?\n",
      "Answer: I used IDE tools to streamline debugging.\n",
      "Probabilities: P(incorrect)= 0.0016, P(correct)= 0.9984\n",
      "Prediction: correct\n",
      "\n",
      "Test Case 4:\n",
      "Input: Question: What was your role at WH Solutions?\n",
      "Answer: I was an Intern Software Engineer, working on full-stack application development.\n",
      "Probabilities: P(incorrect)= 0.9698, P(correct)= 0.0302\n",
      "Prediction: incorrect\n",
      "\n",
      "Test Case 5:\n",
      "Input: Question: What was your role at WH Solutions?\n",
      "Answer: I was a project manager overseeing software development.\n",
      "Probabilities: P(incorrect)= 0.9992, P(correct)= 0.0008\n",
      "Prediction: incorrect\n",
      "\n"
     ]
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T12:43:21.026913Z",
     "start_time": "2025-07-26T12:43:15.952759Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install pandas matplotlib seaborn\n",
    "!pip install tabulate\n",
    "!pip install openpyxl\n",
    "\n"
   ],
   "id": "38d0e218dc949a9b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(57115) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (2.3.1)\r\n",
      "Requirement already satisfied: matplotlib in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (3.10.3)\r\n",
      "Requirement already satisfied: seaborn in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (0.13.2)\r\n",
      "Requirement already satisfied: numpy>=1.22.4 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from pandas) (2.2.6)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from pandas) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from pandas) (2025.2)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from matplotlib) (1.3.2)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from matplotlib) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from matplotlib) (4.59.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from matplotlib) (1.4.8)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from matplotlib) (25.0)\r\n",
      "Requirement already satisfied: pillow>=8 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from matplotlib) (11.3.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from matplotlib) (3.2.3)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\r\n",
      "\u001B[33mWARNING: There was an error checking the latest version of pip.\u001B[0m\u001B[33m\r\n",
      "\u001B[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(57119) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tabulate in /Users/dasunsathsara/VVH/FinalYearProject-SmartHire-Backend/.venv/lib/python3.10/site-packages (0.9.0)\r\n",
      "\u001B[33mWARNING: There was an error checking the latest version of pip.\u001B[0m\u001B[33m\r\n",
      "\u001B[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(57120) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\r\n",
      "  Obtaining dependency information for openpyxl from https://files.pythonhosted.org/packages/c0/da/977ded879c29cbd04de313843e76868e6e13408a94ed6b987245dc7c8506/openpyxl-3.1.5-py2.py3-none-any.whl.metadata\r\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\r\n",
      "Collecting et-xmlfile (from openpyxl)\r\n",
      "  Obtaining dependency information for et-xmlfile from https://files.pythonhosted.org/packages/c1/8b/5fe2cc11fee489817272089c4203e679c63b570a5aaeb18d852ae3cbba6a/et_xmlfile-2.0.0-py3-none-any.whl.metadata\r\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\r\n",
      "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m250.9/250.9 kB\u001B[0m \u001B[31m706.5 kB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\r\n",
      "Installing collected packages: et-xmlfile, openpyxl\r\n",
      "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\r\n",
      "\u001B[33mWARNING: There was an error checking the latest version of pip.\u001B[0m\u001B[33m\r\n",
      "\u001B[0m"
     ]
    }
   ],
   "execution_count": 73
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T12:40:33.387385Z",
     "start_time": "2025-07-26T12:40:29.693178Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Prepare display data\n",
    "results = []\n",
    "for i, text in enumerate(test_examples):\n",
    "    with torch.no_grad():\n",
    "        encoded = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
    "        output = model(**encoded)\n",
    "        probs = torch.softmax(output.logits, dim=-1).cpu().numpy()[0]\n",
    "        pred = torch.argmax(output.logits, dim=-1).item()\n",
    "        results.append({\n",
    "            \"Question + Answer\": text,\n",
    "            \"Prediction\": \"correct\" if pred == 1 else \"incorrect\",\n",
    "            \"P(correct)\": round(probs[1], 4),\n",
    "            \"P(incorrect)\": round(probs[0], 4)\n",
    "        })\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "display(df)  # If using Jupyter Notebook\n",
    "print(df.to_markdown())  # CLI-friendly output\n"
   ],
   "id": "d6de0c5ac98b238d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                   Question + Answer Prediction  P(correct)  \\\n",
       "0  Question: What was a key collaboration challen...    correct      0.9973   \n",
       "1  Question: How do you integrate backend APIs wi...    correct      0.9977   \n",
       "2  Question: How did you improve debugging effici...    correct      0.9984   \n",
       "3  Question: What was your role at WH Solutions?\\...  incorrect      0.0302   \n",
       "4  Question: What was your role at WH Solutions?\\...  incorrect      0.0008   \n",
       "\n",
       "   P(incorrect)  \n",
       "0        0.0027  \n",
       "1        0.0023  \n",
       "2        0.0016  \n",
       "3        0.9698  \n",
       "4        0.9992  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question + Answer</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>P(correct)</th>\n",
       "      <th>P(incorrect)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Question: What was a key collaboration challen...</td>\n",
       "      <td>correct</td>\n",
       "      <td>0.9973</td>\n",
       "      <td>0.0027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Question: How do you integrate backend APIs wi...</td>\n",
       "      <td>correct</td>\n",
       "      <td>0.9977</td>\n",
       "      <td>0.0023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Question: How did you improve debugging effici...</td>\n",
       "      <td>correct</td>\n",
       "      <td>0.9984</td>\n",
       "      <td>0.0016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Question: What was your role at WH Solutions?\\...</td>\n",
       "      <td>incorrect</td>\n",
       "      <td>0.0302</td>\n",
       "      <td>0.9698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Question: What was your role at WH Solutions?\\...</td>\n",
       "      <td>incorrect</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.9992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    | Question + Answer                                                                                                                                             | Prediction   |   P(correct) |   P(incorrect) |\n",
      "|---:|:--------------------------------------------------------------------------------------------------------------------------------------------------------------|:-------------|-------------:|---------------:|\n",
      "|  0 | Question: What was a key collaboration challenge you faced at WH Solutions, and how did you address it?                                                       | correct      |       0.9973 |         0.0027 |\n",
      "|    | Answer: I faced challenges coordinating with the frontend team due to misaligned APIs, which I resolved by implementing Swagger for better API documentation. |              |              |                |\n",
      "|  1 | Question: How do you integrate backend APIs with front-end?                                                                                                   | correct      |       0.9977 |         0.0023 |\n",
      "|    | Answer: I use axios to connect React UIs with REST APIs.                                                                                                      |              |              |                |\n",
      "|  2 | Question: How did you improve debugging efficiency?                                                                                                           | correct      |       0.9984 |         0.0016 |\n",
      "|    | Answer: I used IDE tools to streamline debugging.                                                                                                             |              |              |                |\n",
      "|  3 | Question: What was your role at WH Solutions?                                                                                                                 | incorrect    |       0.0302 |         0.9698 |\n",
      "|    | Answer: I was an Intern Software Engineer, working on full-stack application development.                                                                     |              |              |                |\n",
      "|  4 | Question: What was your role at WH Solutions?                                                                                                                 | incorrect    |       0.0008 |         0.9992 |\n",
      "|    | Answer: I was a project manager overseeing software development.                                                                                              |              |              |                |\n"
     ]
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T12:41:12.238482Z",
     "start_time": "2025-07-26T12:41:11.948361Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Count predictions\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(data=df, x=\"Prediction\", palette=\"pastel\")\n",
    "plt.title(\"Prediction Counts\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ],
   "id": "1cb5ef4546c859f5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tm/rvfp5h494516qprtzvrwh8r00000gn/T/ipykernel_40844/246712404.py:7: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.countplot(data=df, x=\"Prediction\", palette=\"pastel\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T12:41:22.250320Z",
     "start_time": "2025-07-26T12:41:22.154914Z"
    }
   },
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "df[[\"P(correct)\", \"P(incorrect)\"]].plot(kind=\"bar\", stacked=False, figsize=(10, 5))\n",
    "plt.title(\"Prediction Probabilities for Each Example\")\n",
    "plt.xticks(ticks=range(len(df)), labels=[f\"Ex {i+1}\" for i in range(len(df))], rotation=45)\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "id": "91dd1e87a03f94c3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-26T12:43:32.938320Z",
     "start_time": "2025-07-26T12:43:32.874943Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df.to_csv(\"model_predictions.csv\", index=False)\n",
    "# or\n",
    "df.to_excel(\"model_predictions.xlsx\", index=False)\n"
   ],
   "id": "f273cbc4d5dfe112",
   "outputs": [],
   "execution_count": 74
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
